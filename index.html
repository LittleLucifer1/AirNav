<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title></title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h1 class="title is-2 publication-title">AirNav:A Large-Scale Real-World UAV Vision-and-Language Navigation Dataset<br>with Natural and Diverse Instructions</h1>
        <div class="is-size-5 publication-authors">
          <span class="author-block">
            <a>Hengxing Cai</a><sup>1*</sup>,
          </span>
          <span class="author-block">
            <a>Yijie Rao</a><sup>2*</sup>,
          </span>
          <span class="author-block">
            <a>Ligang Huang</a><sup>3</sup>,
          </span>
          <span class="author-block">
            <a>Zanyang Zhong</a><sup>1</sup>,
          </span>
          <span class="author-block">
            <a>Jinhan Dong</a><sup>4</sup>,
          </span>
          <br>
          <span class="author-block">
            <a>Jingjun Tan</a><sup>1</sup>,
          </span>
          <span class="author-block">
            <a>Wenhao Lu</a><sup>5</sup>,
          </span>
          <span class="author-block">
            <a>Renxin Zhong</a><sup>1â€ </sup>
          </span>
          <br>
          <span class="author-block">
            (* indicates equal contribution, â€  corresponding author)
          </span>
        </div>

        <div class="is-size-5 publication-authors">
          <span class="author-block"><sup>1</sup>School of Intelligent Systems Engineering, Sun Yat-Sen University</span>,
          <span class="author-block"><sup>2</sup>Beihang University</span>,
          <span class="author-block"><sup>3</sup>Peking University</span>,
          <br>
          <span class="author-block"><sup>4</sup>Beijing University of Posts and Telecommunications</span>,
          <span class="author-block"><sup>5</sup>National University of Defense Technology</span>
        </div>

        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- Arxiv PDF link -->
            <span class="link-block">
              <a href="https://arxiv.org/pdf/2406.14240" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
              </a>
            </span>
                
            &nbsp;&nbsp;&nbsp;&nbsp;
            <!-- Supplementary PDF link -->
              <!-- <span class="link-block">
                <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Supplementary</span>
              </a>
            </span> -->

            <!-- Github link -->
            <span class="link-block">
              <a href="https://anonymous.4open.science/r/AirNav-FB4C" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
              <span>Code</span>
              </a>
            </span>

              <!-- dataset link -->
              <!-- <span class="link-block">
                <a href="https://anonymous.4open.science/r/AirNav-FB4C" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon" style="vertical-align: middle; font-size: 20px;">ðŸ¤—</span>
                    <span style="vertical-align: middle;">Dataset</span>
                </a>
              </span> -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          <p><b>TL;DR</b>: CityNav is a dataset for vision-and-language aerial navigation 
            that consists of human-generated trajectories paired with  descriptions on real-world 3D cities.</p>
            <p class="new-line"></p>
          <img src="static/figures/teaser.png" alt="teaser" class="blend-img-background center-image" style="width: 100%; height: auto;">
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- <hr class="container is-max-desktop separator"> -->

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            We propose AirNav, a large-scale UAV VLN benchmark constructed from real urban aerial data, rather than synthetic environments, with natural and diverse instructions. 
            Additionally, we introduce the AirVLN-R1, which combines Supervised Fine-Tuning and Reinforcement Fine-Tuning to enhance performance and generalization. 
            The feasibility of the model is preliminarily evaluated through real-world tests.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<hr class="container is-max-desktop separator">

<!-- Data construction -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Dataset Construction</h2>
        <div class="content has-text-justified">
          <img src="static/images/data_construction.png" alt="Overview of the AirNav Benchmark Construction Pipeline" class="blend-img-background center-image">
          <p class="new-line"></p>
          <p>
            The AirNav pipeline is designed to bridge the gap between synthetic data and real-world complexity. It consists of three primary stages:
<br>Data Collection & Scene Reconstruction: High-resolution aerial images are captured across diverse urban areas (residential, industrial, etc.) using professional drones. These are processed using Structure-from-Motion (SfM) to create dense 3D reconstructions.
<br>Graph Generation: The system samples nodes within the 3D space to build a navigable connectivity graph, ensuring the paths are realistic for UAV flight.
<br>Instruction Generation: Using a combination of template-based methods and Large Language Models (LLMs), the pipeline generates diverse, natural language instructions that describe landmarks and spatial relationships for each path.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End data construction -->
<hr class="container is-max-desktop separator">

<!-- <hr class="container is-max-desktop separator"> -->
<!-- demonstration video -->
<!-- <section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Web-based 3D Flight Simulator</h2>
        <div class="content has-text-justified">
          <video poster="" id="tree" autoplay controls muted loop>
            <source src="static/videos/citynav_web_demo_mid_quality.mp4"
            type="video/mp4">
          </video>
          <p class="new-line"></p>
          <p>
            To collect trajectory data via the web, we developed a web-based flight simulator 
            that allows users to operate an aerial agent within 3D enviroments.
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->



<!-- Dataset Statistics -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Dataset Statistics</h2>
        <div class="content has-text-justified">
          <img src="static/images/data_statistics.png" alt="statistics of our proposed dataset" class="blend-img-background center-image">
          <p class="new-line"></p>
          <p>
            <strong>Dataset Statistics:</strong> (a) summarizes the statistics of the number of scenes and trajectories for each set, 
            (b) illustrates the distributions for the length of collected trajectories. 
            (c) illustrates the distributions for the description length corresponding to the trajectories, 
            (d) shows the distance distribution of eval splits from the starting point to the goal, 
            (e) shows the episode length of both the shortest path and human demonstration trajectories, 
            and (f) shows action histograms for the shortest path and human demonstration.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<hr class="container is-max-desktop separator">

<!-- AirVLN_R1 architecture -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">AirVLN R1 Architecture</h2>
        <div class="content has-text-justified">
          <img src="static/images/airvln_r1.png" alt="statistics of our proposed dataset" class="blend-img-background center-image">
          <p class="new-line"></p>
          <p>
            <strong>AirVLN-R1</strong> is a multi-modal agent designed to process visual observations and textual instructions simultaneously:
<br>Hybrid Training Strategy: It uniquely combines Supervised Fine-Tuning (SFT) to establish a baseline of instruction-following behavior and Reinforcement Fine-Tuning (RFT) to optimize the agent's decision-making through trial and error.
<br>Perception & Action: The architecture utilizes a visual encoder (often CLIP-based) to extract features from the UAVâ€™s camera feed and a transformer-based policy network to predict the next best movement (action) in the 3D environment.
<br>Reasoning: By leveraging the reasoning capabilities of large models, it can understand complex spatial commands like "Fly past the red building and stop near the circular fountain."
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End AirVLN_R1 architecture -->
<hr class="container is-max-desktop separator">

<!-- Real world -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Real World UAV VLN Deployment</h2>
        <div class="content has-text-justified">
          <img src="static/images/realworld.png" alt="statistics of our proposed dataset" class="blend-img-background center-image">
          <p class="new-line"></p>
          <p>
            To validate the model's practical utility, the researchers conducted physical flight tests:
<br>Cross-Domain Testing: The model was deployed on actual UAV hardware to navigate both outdoor urban environments (similar to the training data) and unseen indoor scenes (testing generalization).
<br>System Integration: The deployment involves an onboard processing unit that handles real-time visual processing, local mapping, and obstacle avoidance while executing the VLN agent's high-level commands.
<br>Feasibility Results: The tests demonstrated that the model trained on AirNav's real-world aerial data generalizes significantly better to physical hardware than models trained purely on synthetic, "perfect" simulations.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Real world -->
<hr class="container is-max-desktop separator">


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @misc{lee2024citynav,
        title={CityNav: Language-Goal Aerial Navigation Dataset with Geographic Information}, 
        author={Hengxing Cai and Yijie Rao and Ligang Huang and Zanyang Zhong and Jinhan Dong and Jingjun Tan and Wenhao Lu and Renxin Zhong},
        year={2026},
        eprint={2406.14240},
        archivePrefix={arXiv}
      }
    </code></pre>
  </div>
</section>

<script>
  document.addEventListener('DOMContentLoaded', function () {
    var carousels = bulmaCarousel.attach('.carousel1', {
      autoplay: false, // Disable the automatic page switch
    });
  });
</script>

<script>
  let currentSlide = 0;
  const slides = document.querySelectorAll('.w-slide');
  const totalSlides = slides.length; 

  const sliderMask = document.getElementById('w-slider-mask-0'); 

  function nextSlide() {
    currentSlide = (currentSlide + 1) % totalSlides; 
    updateSlidePosition();
  }

  function previousSlide() {
    currentSlide = (currentSlide - 1 + totalSlides) % totalSlides; 
    updateSlidePosition();
  }

  function updateSlidePosition() {
    const newTransformValue = `translateX(-${currentSlide * 100}%)`;
    sliderMask.style.transform = newTransformValue; 
    
    updateDots();
  }

  function createDots() {
    const dotsContainer = document.querySelector('.dots-container');
    for (let i = 0; i < totalSlides; i++) {
      const dot = document.createElement('div');
      dot.classList.add('dot');
      dot.addEventListener('click', () => {
        currentSlide = i; 
        updateSlidePosition();
      });
      dotsContainer.appendChild(dot);
    }
  }

  function updateDots() {
    const dots = document.querySelectorAll('.dot');
    dots.forEach((dot, index) => {
      dot.classList.toggle('active', index === currentSlide);
    });
  }


  createDots();
  updateDots();

  setInterval(() => {
    nextSlide();
  }, 10000); 
</script>


<style>
  .container-wrapper {
    display: flex;
    justify-content: center;
    align-items: center;
    /* min-height: 100vh; */
  }

  .custom-width {
    width: 50%;
  }
</style>

<style>
  .enlarged-image {
    width: 120%;
    height: 120%; 
  }
</style>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>